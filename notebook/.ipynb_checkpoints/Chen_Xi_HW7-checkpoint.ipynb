{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Chen_Xi_HW7</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using 1 of my late days.  \n",
    "Name: Xi Chen\n",
    "<br>\n",
    "Github Username: Alicella\n",
    "<br>\n",
    "USC ID: 8869487524"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Multi-class and Multi-Label Classification Using Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Download the Anuran Calls (MFCCs) Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('../data/Frogs_MFCCs.csv')\n",
    "X = df.iloc[:,0:22]\n",
    "y = df.iloc[:,22:25]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MFCCs_ 1</th>\n",
       "      <th>MFCCs_ 2</th>\n",
       "      <th>MFCCs_ 3</th>\n",
       "      <th>MFCCs_ 4</th>\n",
       "      <th>MFCCs_ 5</th>\n",
       "      <th>MFCCs_ 6</th>\n",
       "      <th>MFCCs_ 7</th>\n",
       "      <th>MFCCs_ 8</th>\n",
       "      <th>MFCCs_ 9</th>\n",
       "      <th>MFCCs_10</th>\n",
       "      <th>...</th>\n",
       "      <th>MFCCs_13</th>\n",
       "      <th>MFCCs_14</th>\n",
       "      <th>MFCCs_15</th>\n",
       "      <th>MFCCs_16</th>\n",
       "      <th>MFCCs_17</th>\n",
       "      <th>MFCCs_18</th>\n",
       "      <th>MFCCs_19</th>\n",
       "      <th>MFCCs_20</th>\n",
       "      <th>MFCCs_21</th>\n",
       "      <th>MFCCs_22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152936</td>\n",
       "      <td>-0.105586</td>\n",
       "      <td>0.200722</td>\n",
       "      <td>0.317201</td>\n",
       "      <td>0.260764</td>\n",
       "      <td>0.100945</td>\n",
       "      <td>-0.150063</td>\n",
       "      <td>-0.171128</td>\n",
       "      <td>0.124676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.156436</td>\n",
       "      <td>0.082245</td>\n",
       "      <td>0.135752</td>\n",
       "      <td>-0.024017</td>\n",
       "      <td>-0.108351</td>\n",
       "      <td>-0.077623</td>\n",
       "      <td>-0.009568</td>\n",
       "      <td>0.057684</td>\n",
       "      <td>0.118680</td>\n",
       "      <td>0.014038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.171534</td>\n",
       "      <td>-0.098975</td>\n",
       "      <td>0.268425</td>\n",
       "      <td>0.338672</td>\n",
       "      <td>0.268353</td>\n",
       "      <td>0.060835</td>\n",
       "      <td>-0.222475</td>\n",
       "      <td>-0.207693</td>\n",
       "      <td>0.170883</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.254341</td>\n",
       "      <td>0.022786</td>\n",
       "      <td>0.163320</td>\n",
       "      <td>0.012022</td>\n",
       "      <td>-0.090974</td>\n",
       "      <td>-0.056510</td>\n",
       "      <td>-0.035303</td>\n",
       "      <td>0.020140</td>\n",
       "      <td>0.082263</td>\n",
       "      <td>0.029056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152317</td>\n",
       "      <td>-0.082973</td>\n",
       "      <td>0.287128</td>\n",
       "      <td>0.276014</td>\n",
       "      <td>0.189867</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>-0.242234</td>\n",
       "      <td>-0.219153</td>\n",
       "      <td>0.232538</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.237384</td>\n",
       "      <td>0.050791</td>\n",
       "      <td>0.207338</td>\n",
       "      <td>0.083536</td>\n",
       "      <td>-0.050691</td>\n",
       "      <td>-0.023590</td>\n",
       "      <td>-0.066722</td>\n",
       "      <td>-0.025083</td>\n",
       "      <td>0.099108</td>\n",
       "      <td>0.077162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.224392</td>\n",
       "      <td>0.118985</td>\n",
       "      <td>0.329432</td>\n",
       "      <td>0.372088</td>\n",
       "      <td>0.361005</td>\n",
       "      <td>0.015501</td>\n",
       "      <td>-0.194347</td>\n",
       "      <td>-0.098181</td>\n",
       "      <td>0.270375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.317084</td>\n",
       "      <td>-0.011567</td>\n",
       "      <td>0.100413</td>\n",
       "      <td>-0.050224</td>\n",
       "      <td>-0.136009</td>\n",
       "      <td>-0.177037</td>\n",
       "      <td>-0.130498</td>\n",
       "      <td>-0.054766</td>\n",
       "      <td>-0.018691</td>\n",
       "      <td>0.023954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.087817</td>\n",
       "      <td>-0.068345</td>\n",
       "      <td>0.306967</td>\n",
       "      <td>0.330923</td>\n",
       "      <td>0.249144</td>\n",
       "      <td>0.006884</td>\n",
       "      <td>-0.265423</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>0.266434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.298524</td>\n",
       "      <td>0.037439</td>\n",
       "      <td>0.219153</td>\n",
       "      <td>0.062837</td>\n",
       "      <td>-0.048885</td>\n",
       "      <td>-0.053074</td>\n",
       "      <td>-0.088550</td>\n",
       "      <td>-0.031346</td>\n",
       "      <td>0.108610</td>\n",
       "      <td>0.079244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MFCCs_ 1  MFCCs_ 2  MFCCs_ 3  MFCCs_ 4  MFCCs_ 5  MFCCs_ 6  MFCCs_ 7  \\\n",
       "0       1.0  0.152936 -0.105586  0.200722  0.317201  0.260764  0.100945   \n",
       "1       1.0  0.171534 -0.098975  0.268425  0.338672  0.268353  0.060835   \n",
       "2       1.0  0.152317 -0.082973  0.287128  0.276014  0.189867  0.008714   \n",
       "3       1.0  0.224392  0.118985  0.329432  0.372088  0.361005  0.015501   \n",
       "4       1.0  0.087817 -0.068345  0.306967  0.330923  0.249144  0.006884   \n",
       "\n",
       "   MFCCs_ 8  MFCCs_ 9  MFCCs_10  ...  MFCCs_13  MFCCs_14  MFCCs_15  MFCCs_16  \\\n",
       "0 -0.150063 -0.171128  0.124676  ... -0.156436  0.082245  0.135752 -0.024017   \n",
       "1 -0.222475 -0.207693  0.170883  ... -0.254341  0.022786  0.163320  0.012022   \n",
       "2 -0.242234 -0.219153  0.232538  ... -0.237384  0.050791  0.207338  0.083536   \n",
       "3 -0.194347 -0.098181  0.270375  ... -0.317084 -0.011567  0.100413 -0.050224   \n",
       "4 -0.265423 -0.172700  0.266434  ... -0.298524  0.037439  0.219153  0.062837   \n",
       "\n",
       "   MFCCs_17  MFCCs_18  MFCCs_19  MFCCs_20  MFCCs_21  MFCCs_22  \n",
       "0 -0.108351 -0.077623 -0.009568  0.057684  0.118680  0.014038  \n",
       "1 -0.090974 -0.056510 -0.035303  0.020140  0.082263  0.029056  \n",
       "2 -0.050691 -0.023590 -0.066722 -0.025083  0.099108  0.077162  \n",
       "3 -0.136009 -0.177037 -0.130498 -0.054766 -0.018691  0.023954  \n",
       "4 -0.048885 -0.053074 -0.088550 -0.031346  0.108610  0.079244  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Family</th>\n",
       "      <th>Genus</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Family      Genus         Species\n",
       "0  Leptodactylidae  Adenomera  AdenomeraAndre\n",
       "1  Leptodactylidae  Adenomera  AdenomeraAndre\n",
       "2  Leptodactylidae  Adenomera  AdenomeraAndre\n",
       "3  Leptodactylidae  Adenomera  AdenomeraAndre\n",
       "4  Leptodactylidae  Adenomera  AdenomeraAndre"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Train a classifier for each label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Accuracy score/ Exact match metric calculates subset accuracy meaning the predicted set of labels should exactly match with the true set of labels. This is usually too restrict for multilabel classification. \n",
    "\n",
    " Hamming Loss calculates the fraction of the wrong labels to the total number of labels.  \n",
    " \n",
    " I compared the results using these two metrics in (ii) - (iv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) Train a SVM for each of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 6.414205312236928, 'gamma': 2.611111111111111}\n",
      "best cv score: 0.9938448673041119\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# default kernel is Guassian/RBF, default decision_function_shape='ovr'\n",
    "clf = SVC(random_state=0)\n",
    "selector_fml = GridSearchCV(clf, param_grid={'C': np.logspace(0.1, 1, 15), 'gamma': np.linspace(2.5, 3.5, 10)}, cv=10, n_jobs=-1)\n",
    "selector_fml.fit(X_train, y_train['Family'])\n",
    "\n",
    "print(selector_fml.best_params_)\n",
    "print(\"best cv score:\", selector_fml.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score for class Family 0.9939786938397406\n"
     ]
    }
   ],
   "source": [
    "print(\"test score for class Family\", selector_fml.score(X_test, y_test['Family']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 7.437527275659048, 'gamma': 2.5555555555555554}\n",
      "best cv score: 0.9910627504812396\n"
     ]
    }
   ],
   "source": [
    "selector_gns = GridSearchCV(clf, param_grid={'C': np.logspace(0.1, 1, 15), 'gamma': np.linspace(1, 3, 10)}, cv=10, n_jobs=-1)\n",
    "selector_gns.fit(X_train, y_train['Genus'])\n",
    "\n",
    "print(selector_gns.best_params_)\n",
    "print(\"best cv score:\", selector_gns.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score for class Genus 0.9888837424733673\n"
     ]
    }
   ],
   "source": [
    "print(\"test score for class Genus\", selector_gns.score(X_test, y_test['Genus']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 9.999999999999998, 'gamma': 2.7222222222222223}\n",
      "best cv score: 0.9910627504812396\n"
     ]
    }
   ],
   "source": [
    "selector_spc = GridSearchCV(clf, param_grid={'C': np.logspace(0.1, 1.5, 15), 'gamma': np.linspace(2.5, 3.5, 10)}, cv=10, n_jobs=-1)\n",
    "selector_spc.fit(X_train, y_train['Species'])\n",
    "\n",
    "print(selector_spc.best_params_)\n",
    "print(\"best cv score:\", selector_spc.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test score for class Species 0.9888837424733673\n"
     ]
    }
   ],
   "source": [
    "print(\"test score for class Species\", selector_spc.score(X_test, y_test['Species']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, hamming_loss\n",
    "                  \n",
    "def hamming_score(y_true, y_pred):\n",
    "    '''\n",
    "    Compute the hamming score for the multi-label case.\n",
    "    '''\n",
    "    # part of the code of this function refers to https://github.com/ruch0401\n",
    "    missclf_labels = 0\n",
    "    for truth, pred in zip(y_true, y_pred):\n",
    "        miss = (truth != pred)\n",
    "        missclf_labels += np.sum(miss)\n",
    "    score = 1 - missclf_labels / (y_true.shape[0] * y_true.shape[1])\n",
    "    \n",
    "    return score\n",
    "    \n",
    "def exact_match_accuracy(y_true, y_pred):\n",
    "    '''\n",
    "    Compute the exact match accuracy for the multi-label case.\n",
    "    '''\n",
    "    # Check if the shapes of y_true and y_pred are the same\n",
    "    if y_true.shape != y_pred.shape:\n",
    "        raise ValueError(\"Input shapes do not match.\")\n",
    "\n",
    "    num_samples = y_true.shape[0]\n",
    "    correct_matches = 0\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        if np.array_equal(y_true[i], y_pred[i]):\n",
    "            correct_matches += 1\n",
    "\n",
    "    accuracy = correct_matches / num_samples\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming score: 0.9905820595954917\n",
      "Exact match accuracy: 0.9861046780917091\n"
     ]
    }
   ],
   "source": [
    "y_pred_fml = selector_fml.predict(X_test)\n",
    "y_pred_gns = selector_gns.predict(X_test)\n",
    "y_pred_spc = selector_spc.predict(X_test)\n",
    "y_pred = np.column_stack((y_pred_fml, y_pred_gns, y_pred_spc))\n",
    "y_true = np.array(np.column_stack((y_test['Family'], y_test['Genus'], y_test['Species'])))\n",
    "\n",
    "print('Hamming score:', hamming_score(y_true, y_pred))\n",
    "print('Exact match accuracy:', exact_match_accuracy(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii) Repeat 1(b)ii with L1-penalized SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params for class Family : {'linearsvc__C': 0.6158482110660264}\n",
      "best cv score for class Family : 0.9410264602859038\n",
      "test score for class Family : 0.9282075034738305\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params for class Genus : {'linearsvc__C': 9.412049672680666}\n",
      "best cv score for class Genus : 0.9527422764997319\n",
      "test score for class Genus : 0.9416396479851783\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params for class Species : {'linearsvc__C': 1.5283067326587687}\n",
      "best cv score for class Species : 0.9604839218656316\n",
      "test score for class Species : 0.9587772116720704\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "clf_scaled = make_pipeline(StandardScaler(), LinearSVC(penalty='l1', dual=\"auto\", random_state=0, max_iter=5000))\n",
    "labels = ['Family', 'Genus', 'Species']\n",
    "\n",
    "y_pred_l1 = []\n",
    "\n",
    "for label in labels:\n",
    "    selector_l1 = GridSearchCV(clf_scaled, param_grid={'linearsvc__C': np.logspace(-1, 1.5, 20)}, cv=10, n_jobs=-1)\n",
    "    selector_l1.fit(X_train, y_train[label])\n",
    "    \n",
    "    y_pred_l1.append(selector_l1.predict(X_test))\n",
    "    \n",
    "    print(\"best params for class\", label, \":\", selector_l1.best_params_)\n",
    "    print(\"best cv score for class\", label, \":\", selector_l1.best_score_)\n",
    "    print(\"test score for class\", label, \":\", selector_l1.score(X_test, y_test[label]))\n",
    "    print(\"---------------------------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming score: 0.9428747877103597\n",
      "Exact match accuracy: 0.9129226493747105\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.column_stack(y_pred_l1)\n",
    "\n",
    "print('Hamming score:', hamming_score(y_true, y_pred))\n",
    "print('Exact match accuracy:', exact_match_accuracy(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iv) Repeat 1(b)iii by using SMOTE or any other method for imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params for class Family : {'linearsvc__C': 0.26366508987303583}\n",
      "best cv score for class Family : 0.9512698538702231\n",
      "test score for class Family : 0.9087540528022232\n",
      "---------------------------------------------\n",
      "best params for class Genus : {'linearsvc__C': 143.8449888287663}\n",
      "best cv score for class Genus : 0.9573564333615856\n",
      "test score for class Genus : 0.9018063918480778\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alicella/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params for class Species : {'linearsvc__C': 20.6913808111479}\n",
      "best cv score for class Species : 0.9633428688189621\n",
      "test score for class Species : 0.9615562760537286\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "y_pred_sm = []\n",
    "\n",
    "clf_scaled = make_pipeline(StandardScaler(), LinearSVC(penalty='l1', dual=\"auto\", random_state=0, max_iter=5000))\n",
    "\n",
    "for label in labels:\n",
    "    X_res, y_res = sm.fit_resample(X_train, y_train[label])\n",
    "    selector_l1s = GridSearchCV(clf_scaled, param_grid={'linearsvc__C': np.logspace(-1, 3, 20)}, cv=10, n_jobs=-1)\n",
    "    selector_l1s.fit(X_res, y_res)\n",
    "    y_pred_sm.append(selector_l1s.predict(X_test))\n",
    "\n",
    "    print(\"best params for class\", label, \":\", selector_l1s.best_params_)\n",
    "    print(\"best cv score for class\", label, \":\", selector_l1s.best_score_)\n",
    "    print(\"test score for class\", label, \":\", selector_l1s.score(X_test, y_test[label]))\n",
    "    print(\"---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming score: 0.9240389069013433\n",
      "Exact match accuracy: 0.8550254747568319\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.column_stack(y_pred_sm)\n",
    "\n",
    "print('Hamming score:', hamming_score(y_true, y_pred))\n",
    "print('Exact match accuracy:', exact_match_accuracy(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison between (ii) - (iv):  \n",
    "- Hamming score is higher than exact match accuracy for all three classifier sets.\n",
    "- SVMs without L1 penalty has the highest hamming score and exact match accuracy.\n",
    "- SMOTE worsens the performance of L1-penalized SVMs, resulting in lower hamming score and exact match accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. K-Means Clustering on a Multi-Class and Multi-Label Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Use k-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "def get_best_k(X, rs=0):\n",
    "    '''\n",
    "    Compute the best k for the KMeans clustering using silhouette score.\n",
    "    Random state is specified by rs.\n",
    "    '''\n",
    "    \n",
    "    best_k = 2\n",
    "    best_score = 0\n",
    "\n",
    "    for k in range(2, 51):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=rs, n_init=10)\n",
    "        kmeans.fit(X)\n",
    "        score = silhouette_score(X, kmeans.labels_)\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_k = k\n",
    "    \n",
    "    return best_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) i. Determine which family, genus, species is the majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_label_clusters(kmeans):\n",
    "    \"\"\"\n",
    "    return a dictionary matching each cluster label to a numpy array of true labels\n",
    "    \"\"\"\n",
    "    cluster_labels = kmeans.labels_\n",
    "    unique, counts = np.unique(cluster_labels, return_counts=True)\n",
    "    # print(np.asarray((unique, counts)).T)\n",
    "\n",
    "    clusters = {label: [] for label in unique}\n",
    "\n",
    "    # Iterate over each instance and append true label to the corresponding cluster\n",
    "    for i, label in enumerate(cluster_labels):\n",
    "        true_label = y.iloc[i]\n",
    "        clusters[label].append(true_label)\n",
    "\n",
    "    # Convert lists to numpy arrays for each cluster\n",
    "    for label in clusters.keys():\n",
    "        clusters[label] = np.array(clusters[label])\n",
    "\n",
    "    return clusters\n",
    "\n",
    "def get_labels_majority_in_each_cluster(clusters):\n",
    "    \"\"\"\n",
    "    Find the majority class of each label in each cluster.\n",
    "    \"\"\"\n",
    "\n",
    "    cluster_nums = [0, 1, 2, 3]\n",
    "    true_labels = ['family', 'genus', 'species']\n",
    "\n",
    "    family_majority = []\n",
    "    genus_majority = []\n",
    "    species_majority = []\n",
    "\n",
    "    for cluster_idx in cluster_nums:\n",
    "        for true_label_idx in range(len(true_labels)):\n",
    "            var = clusters[cluster_idx][:,true_label_idx]\n",
    "            unique_classes, counts = np.unique(var, return_counts=True)\n",
    "            majority_class = unique_classes[np.argmax(counts)]\n",
    "            if true_label_idx == 0:\n",
    "                family_majority.append(majority_class)\n",
    "            elif true_label_idx == 1:\n",
    "                genus_majority.append(majority_class)\n",
    "            else:\n",
    "                species_majority.append(majority_class)\n",
    "\n",
    "    result = pd.DataFrame({'cluster': cluster_nums, 'family_majority': family_majority, 'genus_majority': genus_majority, 'species_majority': species_majority})\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Calculate the average Hamming distance, Hamming score, and Hamming loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import hamming_loss\n",
    "\n",
    "# def get_hamming_distance(y_true, y_pred):\n",
    "#     '''\n",
    "#     Compute the hamming distance between two multi-label vectors.\n",
    "#     '''\n",
    "#     # if y_true.shape != y_pred.shape:\n",
    "#     #     raise ValueError(\"Input shapes do not match.\")\n",
    "\n",
    "#     num_samples = y_true.shape[0]\n",
    "#     hamming_distance = 0\n",
    "    \n",
    "#     for i in range(num_samples):\n",
    "#         hamming_distance += np.sum(y_true[i] != y_pred[i])\n",
    "\n",
    "#     return hamming_distance\n",
    "\n",
    "# for k in clusters.keys():\n",
    "#     majority = majority_res.loc[majority_res['cluster'] == k].iloc[0:,1:4]\n",
    "#     true_labels = clusters[k]\n",
    "    \n",
    "#     for y_true in true_labels:\n",
    "#         y_true.resize(1,3)\n",
    "#         print(get_hamming_distance(y_true, majority))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following two functions refers to https://github.com/ruch0401\n",
    "def get_majority(K, labels, y):\n",
    "    majority = pd.DataFrame(columns=y.columns)\n",
    "    for k in range(K):\n",
    "        idx, = np.where(labels == k)\n",
    "        samples = y.iloc[idx, :]\n",
    "        row = []\n",
    "        for l in y.columns:\n",
    "            row.append(samples.loc[:, l].value_counts().index[0])\n",
    "        majority.loc[k] = row\n",
    "    return majority\n",
    "    \n",
    "def hamming_metrics(majority, labels, y):\n",
    "    error_label_num = 0\n",
    "    for i in range(len(majority)):\n",
    "        idx, = np.where(labels == i)\n",
    "        for label in y.loc[idx].values:\n",
    "            error = label != majority.loc[i].values\n",
    "            error_label_num += np.sum(error)\n",
    "    hamming_distance = error_label_num / y.shape[0]\n",
    "    hamming_loss = error_label_num / (y.shape[0] * y.shape[1])\n",
    "    return hamming_distance, hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo(n):\n",
    "    hm_dist = []\n",
    "    hm_loss = []\n",
    "    hm_score = []\n",
    "\n",
    "    for i in range(1, n+1):\n",
    "        print(\"Monte Carlo Iteration #\", i)\n",
    "        \n",
    "        best_k = get_best_k(X, rs=i)\n",
    "        print(\"Best K:\", best_k)\n",
    "\n",
    "        kmeans = KMeans(n_clusters=best_k, random_state=i, n_init=10).fit(X)\n",
    "        clusters = get_true_label_clusters(kmeans) \n",
    "        majority_res = get_labels_majority_in_each_cluster(clusters)\n",
    "        print(majority_res)\n",
    "        \n",
    "        labels = kmeans.fit_predict(X)\n",
    "        majority = get_majority(best_k, labels, y)\n",
    "        dist, loss = hamming_metrics(majority, labels, y)\n",
    "        score = 1 - loss\n",
    "        hm_dist.append(dist)\n",
    "        hm_loss.append(loss)\n",
    "        hm_score.append(score)\n",
    "        print(f\"Hamming Distance: {round(dist, 4)}  Hamming Loss: {round(loss, 4)}  Hamming Score: {round(score, 4)}\")\n",
    "        print(\"---------------------------------------------\")\n",
    "\n",
    "    return hm_dist, hm_loss, hm_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do (a)-(c) for 50 Monte-Carlo simulation.   \n",
    "In each iteration, the majority of the three labels in each cluster is displayed in a table.  \n",
    "The average Hamming distance, Hamming score and Hamming loss are displayed below the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monte Carlo Iteration # 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hamming_distances, hamming_losses, hamming_scores \u001b[38;5;241m=\u001b[39m monte_carlo(\u001b[38;5;241m50\u001b[39m)\n",
      "Cell \u001b[0;32mIn[24], line 9\u001b[0m, in \u001b[0;36mmonte_carlo\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMonte Carlo Iteration #\u001b[39m\u001b[38;5;124m\"\u001b[39m, i)\n\u001b[0;32m----> 9\u001b[0m     best_k \u001b[38;5;241m=\u001b[39m get_best_k(X, rs\u001b[38;5;241m=\u001b[39mi)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest K:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_k)\n\u001b[1;32m     12\u001b[0m     kmeans \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39mbest_k, random_state\u001b[38;5;241m=\u001b[39mi, n_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(X)\n",
      "Cell \u001b[0;32mIn[21], line 16\u001b[0m, in \u001b[0;36mget_best_k\u001b[0;34m(X, rs)\u001b[0m\n\u001b[1;32m     14\u001b[0m kmeans \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39mk, random_state\u001b[38;5;241m=\u001b[39mrs, n_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     15\u001b[0m kmeans\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m---> 16\u001b[0m score \u001b[38;5;241m=\u001b[39m silhouette_score(X, kmeans\u001b[38;5;241m.\u001b[39mlabels_)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m score \u001b[38;5;241m>\u001b[39m best_score:\n\u001b[1;32m     19\u001b[0m     best_score \u001b[38;5;241m=\u001b[39m score\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/cluster/_unsupervised.py:130\u001b[0m, in \u001b[0;36msilhouette_score\u001b[0;34m(X, labels, metric, sample_size, random_state, **kwds)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m         X, labels \u001b[38;5;241m=\u001b[39m X[indices], labels[indices]\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(silhouette_samples(X, labels, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:187\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    189\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/cluster/_unsupervised.py:282\u001b[0m, in \u001b[0;36msilhouette_samples\u001b[0;34m(X, labels, metric, **kwds)\u001b[0m\n\u001b[1;32m    278\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m metric\n\u001b[1;32m    279\u001b[0m reduce_func \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[1;32m    280\u001b[0m     _silhouette_reduce, labels\u001b[38;5;241m=\u001b[39mlabels, label_freqs\u001b[38;5;241m=\u001b[39mlabel_freqs\n\u001b[1;32m    281\u001b[0m )\n\u001b[0;32m--> 282\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mpairwise_distances_chunked(X, reduce_func\u001b[38;5;241m=\u001b[39mreduce_func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[1;32m    283\u001b[0m intra_clust_dists, inter_clust_dists \u001b[38;5;241m=\u001b[39m results\n\u001b[1;32m    284\u001b[0m intra_clust_dists \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(intra_clust_dists)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:2018\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   2016\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2017\u001b[0m     X_chunk \u001b[38;5;241m=\u001b[39m X[sl]\n\u001b[0;32m-> 2018\u001b[0m D_chunk \u001b[38;5;241m=\u001b[39m pairwise_distances(X_chunk, Y, metric\u001b[38;5;241m=\u001b[39mmetric, n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m   2019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (X \u001b[38;5;129;01mis\u001b[39;00m Y \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   2020\u001b[0m     metric, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2021\u001b[0m ) \u001b[38;5;129;01mis\u001b[39;00m euclidean_distances:\n\u001b[1;32m   2022\u001b[0m     \u001b[38;5;66;03m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[1;32m   2023\u001b[0m     \u001b[38;5;66;03m# i.e. \"l2\"\u001b[39;00m\n\u001b[1;32m   2024\u001b[0m     D_chunk\u001b[38;5;241m.\u001b[39mflat[sl\u001b[38;5;241m.\u001b[39mstart :: _num_samples(X) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:2196\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   2193\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m distance\u001b[38;5;241m.\u001b[39msquareform(distance\u001b[38;5;241m.\u001b[39mpdist(X, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[1;32m   2194\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(distance\u001b[38;5;241m.\u001b[39mcdist, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m-> 2196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:1766\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1763\u001b[0m X, Y, dtype \u001b[38;5;241m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 1766\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(X, Y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m   1768\u001b[0m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[1;32m   1769\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:338\u001b[0m, in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m Y_norm_squared\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;241m1\u001b[39m, Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    334\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible dimensions for Y of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    335\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY_norm_squared of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    336\u001b[0m         )\n\u001b[0;32m--> 338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _euclidean_distances(X, Y, X_norm_squared, Y_norm_squared, squared)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:379\u001b[0m, in \u001b[0;36m_euclidean_distances\u001b[0;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[1;32m    376\u001b[0m     distances \u001b[38;5;241m=\u001b[39m _euclidean_distances_upcast(X, XX, Y, YY)\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;66;03m# if dtype is already float64, no need to chunk and upcast\u001b[39;00m\n\u001b[0;32m--> 379\u001b[0m     distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m safe_sparse_dot(X, Y\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    380\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m XX\n\u001b[1;32m    381\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m YY\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/extmath.py:195\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m     ret \u001b[38;5;241m=\u001b[39m a \u001b[38;5;241m@\u001b[39m b\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m--> 195\u001b[0m     sparse\u001b[38;5;241m.\u001b[39missparse(a)\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    199\u001b[0m ):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/sparse/_base.py:1461\u001b[0m, in \u001b[0;36missparse\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1458\u001b[0m sparray\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m _spbase\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m\n\u001b[0;32m-> 1461\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21missparse\u001b[39m(x):\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Is `x` of a sparse array type?\u001b[39;00m\n\u001b[1;32m   1463\u001b[0m \n\u001b[1;32m   1464\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1487\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, _spbase)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hamming_distances, hamming_losses, hamming_scores = monte_carlo(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm_dist_avg = np.mean(hamming_distances)\n",
    "hm_dist_std = np.std(hamming_distances)\n",
    "hm_loss_avg = np.mean(hamming_losses)\n",
    "hm_loss_std = np.std(hamming_losses)\n",
    "hm_score_avg = np.mean(hamming_scores)\n",
    "hm_score_std = np.std(hamming_scores)\n",
    "hamming_summary = {\n",
    "    'Hamming Distance': {\n",
    "        'avg': hm_dist_avg,\n",
    "        'std': hm_dist_std,\n",
    "    },\n",
    "    'Hamming Score': {\n",
    "        'avg': hm_score_avg,\n",
    "        'std': hm_score_std,\n",
    "    },\n",
    "    'Hamming Loss': {\n",
    "        'avg': hm_loss_avg,\n",
    "        'std': hm_loss_std\n",
    "    }\n",
    "}\n",
    "result_summary = pd.DataFrame(hamming_summary)\n",
    "result_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ISLR 12.6.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: if the picture doesn't show up please check the attachment in the same folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](image-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html  \n",
    "LinearSVC: Similar to SVC with parameter kernel=â€™linearâ€™, but implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.\n",
    "\n",
    "Hamming score for binary multilabel problem: https://hasty.ai/docs/mp-wiki/metrics/hamming-score  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c20c2d94d2527936fe0f3a300eb11db30fed84423423838e2f93b74eb7aaebc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
